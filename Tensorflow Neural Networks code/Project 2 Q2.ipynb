{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 labels:  [9 0 0]\n",
      "\n",
      "First 3 labels (one-hot):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Read Fashion MNIST dataset\n",
    "\n",
    "import util_mnist_reader \n",
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow.contrib.keras as keras\n",
    "import tensorflow as tf\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = util_mnist_reader.load_mnist('.', kind='train')\n",
    "\n",
    "X_test, y_test = util_mnist_reader.load_mnist('.', kind='t10k')\n",
    "#This is to load the dataset provided\n",
    "\n",
    "\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "#We center the dataset to make the algorithm run more efficiently/faster\n",
    "#We take the transpose to get it into the shape 10 by 6,0000 so we have have each sample as its own column instead of its own row.\n",
    "\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "#WITH TENSORFLOW WE CAN DO ONE_HOT_ENCODING IN ONE LINE!!\n",
    "print('First 3 labels: ', y_train[:3])\n",
    "print('\\nFirst 3 labels (one-hot):\\n', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shageenth/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow.contrib.keras as keras\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "# add input layer\n",
    "model.add(keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=X_train_centered.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh') \n",
    ")\n",
    "# add hidden layer\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh')\n",
    "    )\n",
    "# add output layer\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1],\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax')\n",
    "    )\n",
    "\n",
    "# define SGD optimizer\n",
    "sgd_optimizer = keras.optimizers.SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9\n",
    ")\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer=sgd_optimizer,\n",
    "    loss='categorical_crossentropy'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "WARNING:tensorflow:From /home/shageenth/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 5s 84us/sample - loss: 0.7978 - val_loss: 0.5587\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.5138 - val_loss: 0.4786\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s 61us/sample - loss: 0.4571 - val_loss: 0.4446\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.4267 - val_loss: 0.4229\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.4058 - val_loss: 0.4043\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 3s 62us/sample - loss: 0.3901 - val_loss: 0.3949\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.3772 - val_loss: 0.3856\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.3661 - val_loss: 0.3797\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 3s 65us/sample - loss: 0.3567 - val_loss: 0.3739\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.3481 - val_loss: 0.3709\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.3405 - val_loss: 0.3679\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.3335 - val_loss: 0.3652\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 4s 65us/sample - loss: 0.3270 - val_loss: 0.3574\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.3208 - val_loss: 0.3557\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.3153 - val_loss: 0.3507\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 4s 68us/sample - loss: 0.3097 - val_loss: 0.3492\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.3047 - val_loss: 0.3478\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.2997 - val_loss: 0.3465\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.2954 - val_loss: 0.3430\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.2913 - val_loss: 0.3412\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.2869 - val_loss: 0.3379\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.2826 - val_loss: 0.3391\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.2789 - val_loss: 0.3384\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.2753 - val_loss: 0.3357\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.2714 - val_loss: 0.3363\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.2677 - val_loss: 0.3335\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.2642 - val_loss: 0.3360\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.2605 - val_loss: 0.3351\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2576 - val_loss: 0.3350\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.2550 - val_loss: 0.3317\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.2513 - val_loss: 0.3337\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.2487 - val_loss: 0.3319\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 3s 64us/sample - loss: 0.2451 - val_loss: 0.3339\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.2429 - val_loss: 0.3313\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.2399 - val_loss: 0.3282\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.2374 - val_loss: 0.3288\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.2346 - val_loss: 0.3286\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.2319 - val_loss: 0.3325\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2287 - val_loss: 0.3319\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 3s 57us/sample - loss: 0.2263 - val_loss: 0.3285\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.2244 - val_loss: 0.3304\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 4s 66us/sample - loss: 0.2219 - val_loss: 0.3292\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.2197 - val_loss: 0.3282\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.2172 - val_loss: 0.3323\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2151 - val_loss: 0.3312\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.2126 - val_loss: 0.3343\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 41us/sample - loss: 0.2101 - val_loss: 0.3312\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 4s 69us/sample - loss: 0.2077 - val_loss: 0.3320\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 4s 65us/sample - loss: 0.2060 - val_loss: 0.3293\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 45us/sample - loss: 0.2041 - val_loss: 0.3322\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_centered, y_train_onehot,\n",
    "    batch_size=64, epochs=50,\n",
    "    verbose=1, validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [9 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "print('First 3 predictions: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 92.77\n",
      "Test accuracy: 87.36\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "\n",
    "print(f'Training accuracy: {(train_acc * 100):.2f}')\n",
    "\n",
    "# calculate testing accuracy\n",
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "\n",
    "print(f'Test accuracy: {(test_acc * 100):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
